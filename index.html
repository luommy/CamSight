<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live VLM WebUI - Real-time Vision AI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }

        .container {
            max-width: 1600px;
            width: 100%;
            display: flex;
            gap: 20px;
            align-items: flex-start;
        }

        .sidebar {
            width: 350px;
            flex-shrink: 0;
        }

        .main-content {
            flex: 1;
            min-width: 0;
        }

        h1 {
            color: white;
            text-align: center;
            margin-bottom: 10px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .subtitle {
            color: rgba(255, 255, 255, 0.9);
            text-align: center;
            margin-bottom: 30px;
            font-size: 1.1em;
        }

        .header {
            width: 100%;
            margin-bottom: 20px;
        }

        .video-container {
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
            margin-bottom: 20px;
        }

        .video-wrapper {
            position: relative;
            width: 100%;
            border-radius: 15px;
            overflow: hidden;
            background: #000;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }

        video {
            width: 100%;
            height: auto;
            display: block;
        }

        .text-overlay {
            background: rgba(0, 0, 0, 0.9);
            color: #4CAF50;
            padding: 20px 25px;
            font-size: 18px;
            line-height: 1.5;
            border-radius: 15px;
            min-height: 80px;
            display: flex;
            align-items: center;
            transition: all 3s ease-out;
            margin-top: 20px;
        }

        .text-overlay.fade {
            color: #888;
            background: rgba(0, 0, 0, 0.5);
        }

        .metrics {
            position: absolute;
            top: 10px;
            right: 10px;
            background: rgba(0, 0, 0, 0.8);
            color: #4CAF50;
            padding: 8px 12px;
            border-radius: 6px;
            font-size: 12px;
            font-family: 'Courier New', monospace;
            backdrop-filter: blur(5px);
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .metrics div {
            margin: 2px 0;
        }

        .metrics .label {
            color: #aaa;
            display: inline-block;
            width: 80px;
        }

        .metrics .value {
            color: #4CAF50;
            font-weight: bold;
        }

        .control-panel {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 25px;
            margin-bottom: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }

        .control-panel h3 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 16px;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .control-section {
            margin-bottom: 25px;
        }

        .control-section:last-child {
            margin-bottom: 0;
        }

        .control-panel label {
            display: block;
            margin-bottom: 8px;
            color: #555;
            font-weight: 500;
            font-size: 13px;
        }

        .control-panel select,
        .control-panel textarea,
        .control-panel input {
            width: 100%;
            padding: 10px 12px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 14px;
            font-family: inherit;
            margin-bottom: 12px;
            transition: border-color 0.3s ease;
        }

        .control-panel select:focus,
        .control-panel textarea:focus,
        .control-panel input:focus {
            outline: none;
            border-color: #667eea;
        }

        .control-panel textarea {
            resize: vertical;
            min-height: 80px;
            line-height: 1.5;
        }

        .control-panel .btn-update,
        .control-panel .btn-action {
            width: 100%;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px 20px;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            font-size: 14px;
            transition: all 0.3s ease;
            margin-bottom: 10px;
        }

        .control-panel .btn-update:hover:not(:disabled),
        .control-panel .btn-action:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }

        .control-panel .btn-update:disabled,
        .control-panel .btn-action:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .toggle-section {
            cursor: pointer;
            user-select: none;
        }

        .collapsible-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }

        .collapsible-content.expanded {
            max-height: 500px;
        }

        .btn-start {
            background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%) !important;
        }

        .btn-stop {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%) !important;
        }

        .status {
            text-align: center;
            margin-top: 20px;
            padding: 15px;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.9);
            font-weight: 500;
        }

        .status.connected {
            color: #27ae60;
        }

        .status.disconnected {
            color: #e74c3c;
        }

        .status.connecting {
            color: #f39c12;
        }

        .info-box {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 10px;
            padding: 20px;
            margin-top: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }

        .info-box h3 {
            color: #667eea;
            margin-bottom: 10px;
        }

        .info-box ul {
            list-style-position: inside;
            color: #555;
            line-height: 1.8;
        }

        .info-box li {
            margin-bottom: 5px;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.8em;
            }

            .video-container {
                padding: 20px;
            }

            button {
                padding: 10px 20px;
                font-size: 14px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>ðŸŽ¥ Live VLM WebUI</h1>
        <p class="subtitle">Real-time vision AI interaction - describe, detect, analyze anything</p>
    </div>

    <div class="container">
        <!-- Left Sidebar: Controls -->
        <div class="sidebar">
            <!-- Connection Controls -->
            <div class="control-panel">
                <h3>âš¡ Connection</h3>
                <button id="startBtn" class="btn-action btn-start">Start VLM Analysis</button>
                <button id="stopBtn" class="btn-action btn-stop" disabled>Stop Analysis</button>
                <div id="status" class="status disconnected">
                    Click "Start" to begin
                </div>
            </div>

            <!-- Model Selection -->
            <div class="control-panel">
                <h3>ðŸ¤– Model Selection</h3>
                <div class="control-section">
                    <label for="modelSelect">Available Models:</label>
                    <select id="modelSelect">
                        <option value="">Loading models...</option>
                    </select>
                    <button id="refreshModelsBtn" class="btn-action">Refresh Models</button>
                </div>
            </div>

            <!-- Prompt Editor -->
            <div class="control-panel">
                <h3 class="toggle-section" onclick="toggleSection('promptSection')">
                    ðŸŽ¯ Prompt Editor <span id="promptToggle">â–¼</span>
                </h3>
                <div id="promptSection" class="collapsible-content expanded">
                    <div class="control-section">
                        <label for="promptPreset">Quick Presets:</label>
                        <select id="promptPreset">
                            <option value="">-- Select a preset --</option>
                            <option value="Describe what you see in this image in one sentence.">Scene Description</option>
                            <option value="List all objects you can see in this image, separated by commas.">Object Detection</option>
                            <option value="Describe the person's activity and what they are doing.">Activity Recognition</option>
                            <option value="Are there any safety hazards visible? Answer with 'ALERT: description' or 'SAFE'.">Safety Monitoring</option>
                            <option value="Describe the facial expressions and emotions of people visible.">Emotion Detection</option>
                            <option value="Provide a detailed description of the scene for a visually impaired person.">Accessibility</option>
                            <option value="Read and transcribe any text visible in the image.">OCR / Text Reading</option>
                            <option value="What are the dominant colors in this image?">Color Analysis</option>
                            <option value="How many people are in this image? State locations.">People Counting</option>
                            <option value="Are there any pets or animals visible? If yes, describe them.">Pet/Animal Detection</option>
                        </select>
                    </div>
                    <div class="control-section">
                        <label for="promptText">Custom Prompt:</label>
                        <textarea id="promptText" placeholder="Enter your custom prompt here...">Describe what you see in this image in one sentence.</textarea>
                        <button id="updatePromptBtn" class="btn-update">Update Prompt</button>
                    </div>
                </div>
            </div>
        </div>

        <!-- Right Main Content: Video Display -->
        <div class="main-content">
            <div class="video-container">
                <div class="video-wrapper">
                    <video id="videoElement" autoplay playsinline muted></video>
                    <div id="metrics" class="metrics" style="display: none;">
                        <div><span class="label">Latency:</span> <span class="value" id="latencyValue">--</span> ms</div>
                        <div><span class="label">Avg:</span> <span class="value" id="avgLatencyValue">--</span> ms</div>
                        <div><span class="label">Count:</span> <span class="value" id="countValue">--</span></div>
                    </div>
                </div>
                
                <div id="textOverlay" class="text-overlay">
                    <span id="vlmText">Waiting for connection...</span>
                </div>
            </div>
        </div>
    </div>

    <div style="max-width: 1600px; margin: 20px auto;">
        <div class="info-box">
            <h3>How it works:</h3>
            <ul>
                <li>Your webcam video is streamed to the server via WebRTC</li>
                <li>A Vision Language Model (VLM) analyzes frames based on your custom prompt</li>
                <li>VLM responses are overlaid on the video and streamed back in real-time</li>
                <li>Use cases: describe scenes, detect objects, monitor activities, accessibility, and more</li>
                <li>Works with any OpenAI-compatible API (vLLM, SGLang, Ollama, etc.)</li>
            </ul>
        </div>
    </div>

    <script>
        const videoElement = document.getElementById('videoElement');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusElement = document.getElementById('status');
        const textOverlay = document.getElementById('textOverlay');
        const vlmText = document.getElementById('vlmText');
        const metricsDiv = document.getElementById('metrics');
        const latencyValue = document.getElementById('latencyValue');
        const avgLatencyValue = document.getElementById('avgLatencyValue');
        const countValue = document.getElementById('countValue');
        const promptPreset = document.getElementById('promptPreset');
        const promptText = document.getElementById('promptText');
        const updatePromptBtn = document.getElementById('updatePromptBtn');
        const modelSelect = document.getElementById('modelSelect');
        const refreshModelsBtn = document.getElementById('refreshModelsBtn');

        let peerConnection = null;
        let localStream = null;
        let websocket = null;
        let fadeTimeout = null;
        let lastText = '';

        // Update status display
        function updateStatus(message, state) {
            statusElement.textContent = message;
            statusElement.className = `status ${state}`;
        }

        // Toggle collapsible sections
        function toggleSection(sectionId) {
            const section = document.getElementById(sectionId);
            const toggle = document.getElementById(sectionId.replace('Section', 'Toggle'));
            if (section.classList.contains('expanded')) {
                section.classList.remove('expanded');
                if (toggle) toggle.textContent = 'â–¶';
            } else {
                section.classList.add('expanded');
                if (toggle) toggle.textContent = 'â–¼';
            }
        }

        // Fetch available models from server
        async function fetchModels() {
            try {
                modelSelect.innerHTML = '<option value="">Loading models...</option>';
                const response = await fetch('/models');
                const data = await response.json();
                
                if (data.models && data.models.length > 0) {
                    modelSelect.innerHTML = '';
                    data.models.forEach(model => {
                        const option = document.createElement('option');
                        option.value = model.id;
                        option.textContent = model.name || model.id;
                        if (model.current) {
                            option.selected = true;
                        }
                        modelSelect.appendChild(option);
                    });
                } else {
                    modelSelect.innerHTML = '<option value="">No models available</option>';
                }
            } catch (error) {
                console.error('Error fetching models:', error);
                modelSelect.innerHTML = '<option value="">Error loading models</option>';
            }
        }

        // Handle model change
        modelSelect.addEventListener('change', async (e) => {
            const newModel = e.target.value;
            if (!newModel) return;

            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({
                    type: 'update_model',
                    model: newModel
                }));
                updateStatus('Model updated!', 'connected');
            } else {
                alert('Please start the VLM analysis first');
            }
        });

        // Refresh models button
        refreshModelsBtn.addEventListener('click', fetchModels);

        // Load models on page load
        window.addEventListener('load', fetchModels);

        // Handle preset selection
        promptPreset.addEventListener('change', (e) => {
            if (e.target.value) {
                promptText.value = e.target.value;
            }
        });

        // Handle prompt update
        updatePromptBtn.addEventListener('click', () => {
            const newPrompt = promptText.value.trim();
            if (!newPrompt) {
                alert('Please enter a prompt');
                return;
            }

            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({
                    type: 'update_prompt',
                    prompt: newPrompt
                }));
                updateStatus('Prompt updated!', 'connected');

                // Visual feedback
                updatePromptBtn.textContent = 'âœ“ Updated!';
                setTimeout(() => {
                    updatePromptBtn.textContent = 'Update Prompt';
                }, 2000);
            } else {
                alert('Please start the VLM analysis first');
            }
        });

        // Connect to WebSocket for text updates
        function connectWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}/ws`;

            websocket = new WebSocket(wsUrl);

            websocket.onopen = () => {
                console.log('WebSocket connected');
            };

            websocket.onmessage = (event) => {
                const data = JSON.parse(event.data);

                if (data.type === 'vlm_response') {
                    // Check if text changed (new generation)
                    if (data.text !== lastText && lastText !== '') {
                        // Remove fade to show fresh text
                        textOverlay.classList.remove('fade');

                        // Clear existing fade timeout
                        if (fadeTimeout) {
                            clearTimeout(fadeTimeout);
                        }

                        // Start fade after 2 seconds
                        fadeTimeout = setTimeout(() => {
                            textOverlay.classList.add('fade');
                        }, 2000);
                    }

                    // Update text
                    vlmText.textContent = data.text;
                    lastText = data.text;

                    // Update metrics
                    if (data.metrics) {
                        metricsDiv.style.display = 'block';
                        latencyValue.textContent = Math.round(data.metrics.last_latency_ms);
                        avgLatencyValue.textContent = Math.round(data.metrics.avg_latency_ms);
                        countValue.textContent = data.metrics.total_inferences;
                    }
                } else if (data.type === 'status') {
                    vlmText.textContent = data.text;
                }
            };

            websocket.onerror = (error) => {
                console.error('WebSocket error:', error);
            };

            websocket.onclose = () => {
                console.log('WebSocket disconnected');
                vlmText.textContent = 'Disconnected from server';
                vlmStatus.textContent = 'Offline';
            };
        }

        // Disconnect WebSocket
        function disconnectWebSocket() {
            if (websocket) {
                websocket.close();
                websocket = null;
            }
        }

        // Start WebRTC connection
        async function start() {
            try {
                // Connect WebSocket for text updates
                connectWebSocket();

                updateStatus('Requesting camera access...', 'connecting');

                // Get local video stream
                localStream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    },
                    audio: false
                });

                updateStatus('Connecting to server...', 'connecting');

                // Create peer connection
                peerConnection = new RTCPeerConnection({
                    iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
                });

                // Add local stream to peer connection
                localStream.getTracks().forEach(track => {
                    peerConnection.addTrack(track, localStream);
                });

                // Handle incoming stream
                peerConnection.ontrack = (event) => {
                    console.log('Received remote track');
                    if (event.streams && event.streams[0]) {
                        videoElement.srcObject = event.streams[0];
                    }
                };

                // Handle connection state changes
                peerConnection.onconnectionstatechange = () => {
                    console.log('Connection state:', peerConnection.connectionState);

                    switch(peerConnection.connectionState) {
                        case 'connected':
                            updateStatus('Connected - AI is analyzing your video!', 'connected');
                            break;
                        case 'disconnected':
                        case 'failed':
                        case 'closed':
                            updateStatus('Connection lost', 'disconnected');
                            stop();
                            break;
                    }
                };

                // Handle ICE candidates
                peerConnection.onicecandidate = (event) => {
                    // ICE candidates are logged automatically by browser devtools if needed
                    // Uncomment the line below if you want to see them in console:
                    // if (event.candidate) console.log('ICE candidate:', event.candidate);
                };

                // Create and send offer
                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);

                // Send offer to server
                const response = await fetch('/offer', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        sdp: peerConnection.localDescription.sdp,
                        type: peerConnection.localDescription.type
                    })
                });

                if (!response.ok) {
                    throw new Error('Failed to establish connection with server');
                }

                const answer = await response.json();

                // Set remote description
                await peerConnection.setRemoteDescription(
                    new RTCSessionDescription(answer)
                );

                // Update UI
                startBtn.disabled = true;
                stopBtn.disabled = false;

            } catch (error) {
                console.error('Error starting connection:', error);
                updateStatus(`Error: ${error.message}`, 'disconnected');
                stop();
            }
        }

        // Stop WebRTC connection
        function stop() {
            // Disconnect WebSocket
            disconnectWebSocket();

            // Clear fade timeout
            if (fadeTimeout) {
                clearTimeout(fadeTimeout);
                fadeTimeout = null;
            }

            // Stop local stream
            if (localStream) {
                localStream.getTracks().forEach(track => track.stop());
                localStream = null;
            }

            // Close peer connection
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }

            // Clear video
            videoElement.srcObject = null;

            // Update UI
            startBtn.disabled = false;
            stopBtn.disabled = true;
            updateStatus('Stopped', 'disconnected');

            // Reset text overlay
            vlmText.textContent = 'Waiting for connection...';
            textOverlay.classList.remove('fade');
            lastText = '';

            // Hide metrics
            metricsDiv.style.display = 'none';
        }

        // Event listeners
        startBtn.addEventListener('click', start);
        stopBtn.addEventListener('click', stop);

        // Cleanup on page unload
        window.addEventListener('beforeunload', stop);
    </script>
</body>
</html>

